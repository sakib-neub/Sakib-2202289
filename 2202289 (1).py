# -*- coding: utf-8 -*-
"""2202289.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Az9a8hoQRLJ-TQovv5KlWqyLXC4W5qet
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
from scipy.signal import find_peaks

from google.colab import files
uploaded =files.upload()

import io
data=pd.read_csv(io.BytesIO(uploaded['combined_lagEDA.csv']))

# View the 1st few rows of data
print(data.head())

# View the last few rows of data
print(data.tail())

# Get summary statistics of data
print(data.describe())

print(data.isnull().sum())

data.plot(kind='scatter', x='HRR_Min', y='Stress')

# Compute the correlation matrix
corr_matrix = data.corr()

# Create a heatmap of the correlation matrix
import seaborn as sns
sns.heatmap(corr_matrix, annot=True)

#if any null value present then fill that with mean value
data.fillna(data.mean(), inplace=True)

#check if any duplicate value present
print(data.duplicated().sum())

data.head(50)

#covert Stress feature into integer variable
data['Stress'] = data['Stress'].astype(int)

corr_matrix['Stress']

from sklearn.model_selection import train_test_split

#store all data except stress column into x variable
x=data.iloc[:,:-1]
x

#store stress  column into y variable
y=data.iloc[:,-1]
y

#spliting data into training and testing sets
xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.20)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import mutual_info_classif

kbest = SelectKBest(mutual_info_classif,k=10)
slectfeture = kbest.fit(xtrain,ytrain)

#Select some specific feature
xtrain.columns[slectfeture.get_support()]

x1=data[['14','2','1','EDAR_Min','EDAR_Max','HRR_Min','HRR_Max','TEMPR_Mean','TEMPR_Min','TEMPR_Max']]

x1.head(1)

x1train,x1test,y1train,y1test = train_test_split(x1,y,test_size = 0.20)

x1train.head(1)

#import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier

# model1 = AdaBoostClassifier()
# model1.fit(x1train,y1train)

# AdaBoostClassifier()

#see result using this model
# print('train score',model1.score(x1train,y1train))
# print('test score',model1.score(x1test,y1test))

from sklearn.feature_selection import SelectPercentile
from sklearn.feature_selection import mutual_info_classif

sp = SelectPercentile(mutual_info_classif,percentile = 2)
slectfeature2 = sp.fit(xtrain,ytrain)

xtrain.columns[slectfeature2.get_support()]

xtrain.head(20)

model2 = AdaBoostClassifier()
model2.fit(xtrain,ytrain)

AdaBoostClassifier()

print('train score',model2.score(xtrain,ytrain))
print('test score',model2.score(xtest,ytest))

imp = model2.feature_importances_
imp = pd.DataFrame(imp)

feature = xtrain.columns
feature = pd.DataFrame(feature)

importfeature = pd.concat([imp,feature],axis=1)
importfeature.columns=['importace','feature']

importfeature

sns.barplot(x= importfeature['feature'],y = importfeature['importace'])
plt.tick_params(rotation =90)

from sklearn.feature_selection import SelectFromModel
sfm = SelectFromModel(model2, threshold=0)

importfeature = importfeature.loc[importfeature['importace'] > 0]

#see the data which are important for this model
importfeature

sns.barplot(x= importfeature['feature'],y = importfeature['importace'])
plt.tick_params(rotation =90)

x2 = data[['EDAR_Mean','EDAR_Min','EDAR_Max','EDAR_Std','EDAR_Amphitude','HRR_Mean','HRR_Max','HRR_Std','TEMPR_Mean','TEMPR_Max','TEMPR_Std']]

x2.head(2)

x2train,x2test,y2train,y2test = train_test_split(x2,y,test_size = 0.20)

x2train.head(2)

#import another (RandomForestClassifier)to incressing accuracy
from sklearn.ensemble import RandomForestClassifier

# print('train score',model2.score(xtrain,ytrain))
# print('test score',model2.score(xtest,ytest))

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

model3 = RandomForestClassifier()
model3.fit(x2train,y2train)

print('train score',model3.score(x2train,y2train))
print('test accuracy',model3.score(x2test,y2test))

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

clf = RandomForestClassifier(n_estimators=50,max_depth=20)

# Split the  data
tr, ts, tr_labels, ts_labels = train_test_split(x2,y,test_size = 0.20, random_state=30)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(tr, tr_labels.values.ravel())

y_pred = clf.predict(ts)

f1score   = f1_score        (ts_labels, y_pred, average = 'macro')
recall    = recall_score    (ts_labels, y_pred, average = 'macro')
precision = precision_score (ts_labels, y_pred, average = 'macro')
accuracy  = accuracy_score  (ts_labels, y_pred)

print('Accuracy =', accuracy)
print('precesion =', precision)
print('recall =', recall) 
print('f1 score =', f1score)

stress_ = np.array([[0.267780,	0.268449,	0.267893,	0.022911,	0.085781,	0.590035,	0.590541,	0.055537,	0.565072,	0.566901,	0.083885]])  # Features (size, bedrooms, bathrooms, latitude, longitude)
predicted_score = clf.predict(stress_)
print("Predicted stress:", predicted_score)

if predicted_score == 0:
    color = "you are safe"
elif predicted_score == 1:
    color = "breath exercise "

elif predicted_score == 2:
    color = "take proper treatment "


print(f"The stress level is {predicted_score} {color}.")